{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#BASELINE\n#Импорт библеотек\nimport pandas as pd\nimport numpy as np\nimport sklearn\nfrom torch.utils.data import DataLoader, Dataset\nimport torch\nfrom PIL import Image\nimport torchvision.transforms as transforms\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nimport os\nfrom sklearn.model_selection import KFold\nimport torch\nimport torch.nn as nn\nfrom torch.nn import CrossEntropyLoss\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nimport seaborn as sns\nfrom torchvision import datasets\nimport torchvision\nfrom torch.utils.data import random_split\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom sklearn.metrics import f1_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import roc_auc_score\nimport random, os\nimport numpy as np\nimport torch\nimport re\nfrom statistics import mean\nimport optuna\nimport joblib\nimport pandas as pd\nfrom sklearn import linear_model\nfrom sklearn import datasets\nfrom sklearn import model_selection\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import make_scorer\nfrom sklearn.preprocessing import RobustScaler\nimport pandas as pd\nimport numpy as np\nimport sklearn\nfrom torch.utils.data import DataLoader, Dataset\nimport torch\nfrom PIL import Image\nimport torchvision.transforms as transforms\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nimport os\nfrom sklearn.model_selection import KFold\nimport torch\nimport torch.nn as nn\nfrom torch.nn import CrossEntropyLoss\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nimport seaborn as sns\nfrom torchvision import datasets\nimport torchvision\nfrom torch.utils.data import random_split\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom sklearn.metrics import f1_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import roc_auc_score\nimport random, os\nimport numpy as np\nimport torch\nimport re\nfrom statistics import mean\nimport optuna\nimport joblib\nimport pandas as pd\nfrom sklearn import linear_model\nfrom sklearn import datasets\nfrom sklearn import model_selection\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import make_scorer\nfrom sklearn.preprocessing import RobustScaler\n!pip install arcgis\nfrom arcgis.gis import GIS\nfrom arcgis.geocoding import reverse_geocode\ngis = GIS(profile=\"your_online_profile\")\nfrom sklearn.compose import ColumnTransformer\ntorch.manual_seed(41)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-14T22:02:57.875187Z","iopub.execute_input":"2022-11-14T22:02:57.875825Z","iopub.status.idle":"2022-11-14T22:03:17.332461Z","shell.execute_reply.started":"2022-11-14T22:02:57.875724Z","shell.execute_reply":"2022-11-14T22:03:17.330825Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: arcgis in /opt/conda/lib/python3.7/site-packages (2.0.1)\nRequirement already satisfied: jupyter-client<=6.1.12 in /opt/conda/lib/python3.7/site-packages (from arcgis) (6.1.12)\nRequirement already satisfied: requests-ntlm in /opt/conda/lib/python3.7/site-packages (from arcgis) (1.1.0)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (from arcgis) (4.9.1)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from arcgis) (1.26.12)\nRequirement already satisfied: geomet in /opt/conda/lib/python3.7/site-packages (from arcgis) (1.0.0)\nRequirement already satisfied: jupyterlab in /opt/conda/lib/python3.7/site-packages (from arcgis) (3.2.9)\nRequirement already satisfied: python-certifi-win32 in /opt/conda/lib/python3.7/site-packages (from arcgis) (1.6.1)\nRequirement already satisfied: cachetools in /opt/conda/lib/python3.7/site-packages (from arcgis) (4.2.4)\nRequirement already satisfied: requests-gssapi in /opt/conda/lib/python3.7/site-packages (from arcgis) (1.2.3)\nRequirement already satisfied: ipywidgets>=7 in /opt/conda/lib/python3.7/site-packages (from arcgis) (7.7.1)\nRequirement already satisfied: requests-toolbelt in /opt/conda/lib/python3.7/site-packages (from arcgis) (0.10.1)\nRequirement already satisfied: cryptography in /opt/conda/lib/python3.7/site-packages (from arcgis) (37.0.2)\nRequirement already satisfied: pandas>=1.3.5 in /opt/conda/lib/python3.7/site-packages (from arcgis) (1.3.5)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from arcgis) (3.5.3)\nRequirement already satisfied: keyring>=23.3.* in /opt/conda/lib/python3.7/site-packages (from arcgis) (23.6.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from arcgis) (1.15.0)\nRequirement already satisfied: ujson>=3 in /opt/conda/lib/python3.7/site-packages (from arcgis) (5.3.0)\nRequirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from arcgis) (1.3.1)\nRequirement already satisfied: widgetsnbextension>=3 in /opt/conda/lib/python3.7/site-packages (from arcgis) (3.6.1)\nRequirement already satisfied: notebook in /opt/conda/lib/python3.7/site-packages (from arcgis) (6.4.12)\nRequirement already satisfied: pyshp>=2 in /opt/conda/lib/python3.7/site-packages (from arcgis) (2.3.1)\nRequirement already satisfied: lerc in /opt/conda/lib/python3.7/site-packages (from arcgis) (0.1.0)\nRequirement already satisfied: numpy>=1.16.2 in /opt/conda/lib/python3.7/site-packages (from arcgis) (1.21.6)\nRequirement already satisfied: requests>=1.27.1 in /opt/conda/lib/python3.7/site-packages (from arcgis) (2.28.1)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7->arcgis) (0.2.0)\nRequirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7->arcgis) (7.33.0)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7->arcgis) (1.1.1)\nRequirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7->arcgis) (6.15.0)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7->arcgis) (5.3.0)\nRequirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<=6.1.12->arcgis) (23.2.0)\nRequirement already satisfied: tornado>=4.1 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<=6.1.12->arcgis) (6.1)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<=6.1.12->arcgis) (2.8.2)\nRequirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<=6.1.12->arcgis) (4.10.0)\nRequirement already satisfied: SecretStorage>=3.2 in /opt/conda/lib/python3.7/site-packages (from keyring>=23.3.*->arcgis) (3.3.2)\nRequirement already satisfied: importlib-metadata>=3.6 in /opt/conda/lib/python3.7/site-packages (from keyring>=23.3.*->arcgis) (4.13.0)\nRequirement already satisfied: jeepney>=0.4.2 in /opt/conda/lib/python3.7/site-packages (from keyring>=23.3.*->arcgis) (0.8.0)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.3.5->arcgis) (2022.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=1.27.1->arcgis) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=1.27.1->arcgis) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=1.27.1->arcgis) (2.1.0)\nRequirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.7/site-packages (from notebook->arcgis) (1.5.5)\nRequirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.7/site-packages (from notebook->arcgis) (6.4.5)\nRequirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from notebook->arcgis) (1.8.0)\nRequirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from notebook->arcgis) (0.15.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from notebook->arcgis) (3.1.2)\nRequirement already satisfied: argon2-cffi in /opt/conda/lib/python3.7/site-packages (from notebook->arcgis) (21.3.0)\nRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook->arcgis) (0.14.1)\nRequirement already satisfied: nbformat in /opt/conda/lib/python3.7/site-packages (from notebook->arcgis) (5.4.0)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.7/site-packages (from cryptography->arcgis) (1.15.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from geomet->arcgis) (8.0.4)\nRequirement already satisfied: jupyter-server~=1.4 in /opt/conda/lib/python3.7/site-packages (from jupyterlab->arcgis) (1.18.0)\nRequirement already satisfied: nbclassic~=0.2 in /opt/conda/lib/python3.7/site-packages (from jupyterlab->arcgis) (0.3.7)\nRequirement already satisfied: jupyterlab-server~=2.3 in /opt/conda/lib/python3.7/site-packages (from jupyterlab->arcgis) (2.10.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from jupyterlab->arcgis) (21.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->arcgis) (0.11.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->arcgis) (3.0.9)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->arcgis) (1.4.3)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->arcgis) (4.33.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->arcgis) (9.1.1)\nRequirement already satisfied: setuptools-scm in /opt/conda/lib/python3.7/site-packages (from python-certifi-win32->arcgis) (7.0.5)\nRequirement already satisfied: wrapt>=1.10.4 in /opt/conda/lib/python3.7/site-packages (from python-certifi-win32->arcgis) (1.12.1)\nRequirement already satisfied: gssapi in /opt/conda/lib/python3.7/site-packages (from requests-gssapi->arcgis) (1.8.2)\nRequirement already satisfied: ntlm-auth>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from requests-ntlm->arcgis) (1.5.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->arcgis) (3.2.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.12->cryptography->arcgis) (2.21)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=3.6->keyring>=23.3.*->arcgis) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=3.6->keyring>=23.3.*->arcgis) (3.8.0)\nRequirement already satisfied: debugpy>=1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7->arcgis) (1.6.0)\nRequirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7->arcgis) (0.1.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7->arcgis) (5.9.1)\nRequirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7->arcgis) (59.8.0)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7->arcgis) (3.0.30)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7->arcgis) (5.1.1)\nRequirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7->arcgis) (2.12.0)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7->arcgis) (0.18.1)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7->arcgis) (0.7.5)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7->arcgis) (0.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7->arcgis) (4.8.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->notebook->arcgis) (2.1.1)\nRequirement already satisfied: websocket-client in /opt/conda/lib/python3.7/site-packages (from jupyter-server~=1.4->jupyterlab->arcgis) (1.3.3)\nRequirement already satisfied: anyio<4,>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from jupyter-server~=1.4->jupyterlab->arcgis) (3.6.1)\nRequirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from jupyterlab-server~=2.3->jupyterlab->arcgis) (0.4)\nRequirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from jupyterlab-server~=2.3->jupyterlab->arcgis) (4.6.1)\nRequirement already satisfied: json5 in /opt/conda/lib/python3.7/site-packages (from jupyterlab-server~=2.3->jupyterlab->arcgis) (0.9.5)\nRequirement already satisfied: babel in /opt/conda/lib/python3.7/site-packages (from jupyterlab-server~=2.3->jupyterlab->arcgis) (2.10.3)\nRequirement already satisfied: notebook-shim>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from nbclassic~=0.2->jupyterlab->arcgis) (0.1.0)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook->arcgis) (5.0.1)\nRequirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook->arcgis) (0.6.0)\nRequirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook->arcgis) (0.2.2)\nRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook->arcgis) (0.8.4)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook->arcgis) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook->arcgis) (4.11.1)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook->arcgis) (0.5.13)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook->arcgis) (1.5.0)\nRequirement already satisfied: fastjsonschema in /opt/conda/lib/python3.7/site-packages (from nbformat->notebook->arcgis) (2.15.3)\nRequirement already satisfied: ptyprocess in /opt/conda/lib/python3.7/site-packages (from terminado>=0.8.3->notebook->arcgis) (0.7.0)\nRequirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.7/site-packages (from argon2-cffi->notebook->arcgis) (21.2.0)\nRequirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from setuptools-scm->python-certifi-win32->arcgis) (2.0.1)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.7/site-packages (from anyio<4,>=3.1.0->jupyter-server~=1.4->jupyterlab->arcgis) (1.2.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7->arcgis) (0.8.3)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.3->jupyterlab->arcgis) (21.4.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.3->jupyterlab->arcgis) (0.18.1)\nRequirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.3->jupyterlab->arcgis) (5.8.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7->arcgis) (0.2.5)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->nbconvert>=5->notebook->arcgis) (2.3.1)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert>=5->notebook->arcgis) (0.5.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7fd7a291f7d0>"},"metadata":{}}]},{"cell_type":"code","source":"#----------------------LSTM\n\nnew[\"id\"] = idxs\nnew[\"crop\"] = Y\nexp = pd.melt(new, id_vars=list(new.iloc[:,70:].columns), value_vars=list(new.iloc[:, :70].columns))\nexp = exp.sort_values(by=['id'])","metadata":{"execution":{"iopub.status.busy":"2022-11-06T15:20:28.861389Z","iopub.execute_input":"2022-11-06T15:20:28.861845Z","iopub.status.idle":"2022-11-06T15:20:29.010778Z","shell.execute_reply.started":"2022-11-06T15:20:28.861810Z","shell.execute_reply":"2022-11-06T15:20:29.009586Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"exp['lag1'] = exp.groupby('id')['value'].shift(1)\nexp['lag1_back'] = exp.groupby('id')['value'].shift(-1)\nexp['lag2'] = exp.groupby('id')['value'].shift(2)\nexp['lag2_back'] = exp.groupby('id')['value'].shift(-2)\nexp['lag3'] = exp.groupby('id')['value'].shift(3)\nexp['lag3_back'] = exp.groupby('id')['value'].shift(-3)\nexp['lag4'] = exp.groupby('id')['value'].shift(4)\nexp['lag4_back'] = exp.groupby('id')['value'].shift(-4)\nexp['lag5'] = exp.groupby('id')['value'].shift(5)\nexp['lag5_back'] = exp.groupby('id')['value'].shift(-5)\nexp = exp.fillna(0)\nexp","metadata":{"execution":{"iopub.status.busy":"2022-11-06T15:20:33.124550Z","iopub.execute_input":"2022-11-06T15:20:33.124936Z","iopub.status.idle":"2022-11-06T15:20:33.449455Z","shell.execute_reply.started":"2022-11-06T15:20:33.124905Z","shell.execute_reply":"2022-11-06T15:20:33.448240Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"        mean_all  area  lenght           0           1           2  \\\n180364  0.298371    23      70 -177.480572   39.614764   28.613844   \n301114  0.298371    23      70 -177.480572   39.614764   28.613844   \n199684  0.298371    23      70 -177.480572   39.614764   28.613844   \n320434  0.298371    23      70 -177.480572   39.614764   28.613844   \n228664  0.298371    23      70 -177.480572   39.614764   28.613844   \n...          ...   ...     ...         ...         ...         ...   \n319613  0.282255    55      12 -238.339057  149.285326 -109.050093   \n247163  0.282255    55      12 -238.339057  149.285326 -109.050093   \n5663    0.282255    55      12 -238.339057  149.285326 -109.050093   \n227843  0.282255    55      12 -238.339057  149.285326 -109.050093   \n218183  0.282255    55      12 -238.339057  149.285326 -109.050093   \n\n        projected_area  projected_area_sq  num_inter    id  ...      lag1  \\\n180364          629400            1542491          0     0  ...  0.000000   \n301114          629400            1542491          0     0  ...  0.011695   \n199684          629400            1542491          0     0  ...  0.061751   \n320434          629400            1542491          0     0  ...  0.047240   \n228664          629400            1542491          0     0  ...  0.048002   \n...                ...                ...        ...   ...  ...       ...   \n319613         1739712            1955312          0  6900  ...  0.423298   \n247163         1739712            1955312          0  6900  ...  0.173955   \n5663           1739712            1955312          0  6900  ...  0.425138   \n227843         1739712            1955312          0  6900  ...  0.148057   \n218183         1739712            1955312          0  6900  ...  0.478788   \n\n       lag1_back      lag2  lag2_back      lag3  lag3_back      lag4  \\\n180364  0.061751  0.000000   0.047240  0.000000   0.048002  0.000000   \n301114  0.047240  0.000000   0.048002  0.000000   0.545858  0.000000   \n199684  0.048002  0.011695   0.545858  0.000000   0.042138  0.000000   \n320434  0.545858  0.061751   0.042138  0.011695   0.068731  0.000000   \n228664  0.042138  0.047240   0.068731  0.061751   0.041628  0.011695   \n...          ...       ...        ...       ...        ...       ...   \n319613  0.425138  0.524171   0.148057  0.118868   0.478788  0.630772   \n247163  0.148057  0.423298   0.478788  0.524171   0.235605  0.118868   \n5663    0.478788  0.173955   0.235605  0.423298   0.000000  0.524171   \n227843  0.235605  0.425138   0.000000  0.173955   0.000000  0.423298   \n218183  0.000000  0.148057   0.000000  0.425138   0.000000  0.173955   \n\n        lag4_back      lag5  lag5_back  \n180364   0.545858  0.000000   0.042138  \n301114   0.042138  0.000000   0.068731  \n199684   0.068731  0.000000   0.041628  \n320434   0.041628  0.000000   0.399879  \n228664   0.399879  0.000000   0.011793  \n...           ...       ...        ...  \n319613   0.235605  0.506861   0.000000  \n247163   0.000000  0.630772   0.000000  \n5663     0.000000  0.118868   0.000000  \n227843   0.000000  0.524171   0.000000  \n218183   0.000000  0.423298   0.000000  \n\n[338100 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_all</th>\n      <th>area</th>\n      <th>lenght</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>projected_area</th>\n      <th>projected_area_sq</th>\n      <th>num_inter</th>\n      <th>id</th>\n      <th>...</th>\n      <th>lag1</th>\n      <th>lag1_back</th>\n      <th>lag2</th>\n      <th>lag2_back</th>\n      <th>lag3</th>\n      <th>lag3_back</th>\n      <th>lag4</th>\n      <th>lag4_back</th>\n      <th>lag5</th>\n      <th>lag5_back</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>180364</th>\n      <td>0.298371</td>\n      <td>23</td>\n      <td>70</td>\n      <td>-177.480572</td>\n      <td>39.614764</td>\n      <td>28.613844</td>\n      <td>629400</td>\n      <td>1542491</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.061751</td>\n      <td>0.000000</td>\n      <td>0.047240</td>\n      <td>0.000000</td>\n      <td>0.048002</td>\n      <td>0.000000</td>\n      <td>0.545858</td>\n      <td>0.000000</td>\n      <td>0.042138</td>\n    </tr>\n    <tr>\n      <th>301114</th>\n      <td>0.298371</td>\n      <td>23</td>\n      <td>70</td>\n      <td>-177.480572</td>\n      <td>39.614764</td>\n      <td>28.613844</td>\n      <td>629400</td>\n      <td>1542491</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.011695</td>\n      <td>0.047240</td>\n      <td>0.000000</td>\n      <td>0.048002</td>\n      <td>0.000000</td>\n      <td>0.545858</td>\n      <td>0.000000</td>\n      <td>0.042138</td>\n      <td>0.000000</td>\n      <td>0.068731</td>\n    </tr>\n    <tr>\n      <th>199684</th>\n      <td>0.298371</td>\n      <td>23</td>\n      <td>70</td>\n      <td>-177.480572</td>\n      <td>39.614764</td>\n      <td>28.613844</td>\n      <td>629400</td>\n      <td>1542491</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.061751</td>\n      <td>0.048002</td>\n      <td>0.011695</td>\n      <td>0.545858</td>\n      <td>0.000000</td>\n      <td>0.042138</td>\n      <td>0.000000</td>\n      <td>0.068731</td>\n      <td>0.000000</td>\n      <td>0.041628</td>\n    </tr>\n    <tr>\n      <th>320434</th>\n      <td>0.298371</td>\n      <td>23</td>\n      <td>70</td>\n      <td>-177.480572</td>\n      <td>39.614764</td>\n      <td>28.613844</td>\n      <td>629400</td>\n      <td>1542491</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.047240</td>\n      <td>0.545858</td>\n      <td>0.061751</td>\n      <td>0.042138</td>\n      <td>0.011695</td>\n      <td>0.068731</td>\n      <td>0.000000</td>\n      <td>0.041628</td>\n      <td>0.000000</td>\n      <td>0.399879</td>\n    </tr>\n    <tr>\n      <th>228664</th>\n      <td>0.298371</td>\n      <td>23</td>\n      <td>70</td>\n      <td>-177.480572</td>\n      <td>39.614764</td>\n      <td>28.613844</td>\n      <td>629400</td>\n      <td>1542491</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.048002</td>\n      <td>0.042138</td>\n      <td>0.047240</td>\n      <td>0.068731</td>\n      <td>0.061751</td>\n      <td>0.041628</td>\n      <td>0.011695</td>\n      <td>0.399879</td>\n      <td>0.000000</td>\n      <td>0.011793</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>319613</th>\n      <td>0.282255</td>\n      <td>55</td>\n      <td>12</td>\n      <td>-238.339057</td>\n      <td>149.285326</td>\n      <td>-109.050093</td>\n      <td>1739712</td>\n      <td>1955312</td>\n      <td>0</td>\n      <td>6900</td>\n      <td>...</td>\n      <td>0.423298</td>\n      <td>0.425138</td>\n      <td>0.524171</td>\n      <td>0.148057</td>\n      <td>0.118868</td>\n      <td>0.478788</td>\n      <td>0.630772</td>\n      <td>0.235605</td>\n      <td>0.506861</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>247163</th>\n      <td>0.282255</td>\n      <td>55</td>\n      <td>12</td>\n      <td>-238.339057</td>\n      <td>149.285326</td>\n      <td>-109.050093</td>\n      <td>1739712</td>\n      <td>1955312</td>\n      <td>0</td>\n      <td>6900</td>\n      <td>...</td>\n      <td>0.173955</td>\n      <td>0.148057</td>\n      <td>0.423298</td>\n      <td>0.478788</td>\n      <td>0.524171</td>\n      <td>0.235605</td>\n      <td>0.118868</td>\n      <td>0.000000</td>\n      <td>0.630772</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5663</th>\n      <td>0.282255</td>\n      <td>55</td>\n      <td>12</td>\n      <td>-238.339057</td>\n      <td>149.285326</td>\n      <td>-109.050093</td>\n      <td>1739712</td>\n      <td>1955312</td>\n      <td>0</td>\n      <td>6900</td>\n      <td>...</td>\n      <td>0.425138</td>\n      <td>0.478788</td>\n      <td>0.173955</td>\n      <td>0.235605</td>\n      <td>0.423298</td>\n      <td>0.000000</td>\n      <td>0.524171</td>\n      <td>0.000000</td>\n      <td>0.118868</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>227843</th>\n      <td>0.282255</td>\n      <td>55</td>\n      <td>12</td>\n      <td>-238.339057</td>\n      <td>149.285326</td>\n      <td>-109.050093</td>\n      <td>1739712</td>\n      <td>1955312</td>\n      <td>0</td>\n      <td>6900</td>\n      <td>...</td>\n      <td>0.148057</td>\n      <td>0.235605</td>\n      <td>0.425138</td>\n      <td>0.000000</td>\n      <td>0.173955</td>\n      <td>0.000000</td>\n      <td>0.423298</td>\n      <td>0.000000</td>\n      <td>0.524171</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>218183</th>\n      <td>0.282255</td>\n      <td>55</td>\n      <td>12</td>\n      <td>-238.339057</td>\n      <td>149.285326</td>\n      <td>-109.050093</td>\n      <td>1739712</td>\n      <td>1955312</td>\n      <td>0</td>\n      <td>6900</td>\n      <td>...</td>\n      <td>0.478788</td>\n      <td>0.000000</td>\n      <td>0.148057</td>\n      <td>0.000000</td>\n      <td>0.425138</td>\n      <td>0.000000</td>\n      <td>0.173955</td>\n      <td>0.000000</td>\n      <td>0.423298</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>338100 rows × 23 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"targets = exp[['crop']].to_numpy().reshape(-1, 70)\n\nexp.drop(['crop','id', 'variable'], axis=1, inplace=True)\nscaler = RobustScaler()\ntrain = scaler.fit_transform(exp)\n#test = scaler.transform(test)\ntrain = train.reshape(-1, 70, train.shape[-1])\nprint(train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T15:28:30.565497Z","iopub.execute_input":"2022-11-06T15:28:30.565930Z","iopub.status.idle":"2022-11-06T15:28:30.849835Z","shell.execute_reply.started":"2022-11-06T15:28:30.565895Z","shell.execute_reply":"2022-11-06T15:28:30.848516Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n  FutureWarning,\n","output_type":"stream"},{"name":"stdout","text":"(4830, 70, 20)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"pressure = targets.squeeze().reshape(-1,1).astype('float32')","metadata":{"execution":{"iopub.status.busy":"2022-11-06T15:31:03.662593Z","iopub.execute_input":"2022-11-06T15:31:03.663064Z","iopub.status.idle":"2022-11-06T15:31:03.672389Z","shell.execute_reply.started":"2022-11-06T15:31:03.663028Z","shell.execute_reply":"2022-11-06T15:31:03.671167Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"(338100, 1)"},"metadata":{}}]},{"cell_type":"code","source":"#train val split (train and targets)\ntrained_x = train[:4000]\nvaled_x = train[4000:]\ntrained_y = targets[:4000]\nvaled_y = targets[4000:]","metadata":{"execution":{"iopub.status.busy":"2022-11-06T16:09:04.835945Z","iopub.execute_input":"2022-11-06T16:09:04.836427Z","iopub.status.idle":"2022-11-06T16:09:04.842301Z","shell.execute_reply.started":"2022-11-06T16:09:04.836373Z","shell.execute_reply":"2022-11-06T16:09:04.841057Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"#Writing custom dataset\nclass CustomDataset(Dataset):\n    def __init__(self, root_dir, ans):\n        self.root_dir = root_dir\n        self.ans = ans\n        \n    \n    def __len__(self):\n        return len(self.root_dir)\n    \n    def __getitem__(self, index):\n        dta = self.root_dir[index]\n        label = self.ans[index][0]\n            \n        return (dta, label)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T16:06:18.458748Z","iopub.execute_input":"2022-11-06T16:06:18.459147Z","iopub.status.idle":"2022-11-06T16:06:18.466852Z","shell.execute_reply.started":"2022-11-06T16:06:18.459115Z","shell.execute_reply":"2022-11-06T16:06:18.465492Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"traindataset = CustomDataset(root_dir = trained_x, ans = trained_y)\nvaldataset = CustomDataset(root_dir = valed_x, ans = valed_y)\ntrainloader = DataLoader(dataset = traindataset, batch_size = 32, shuffle = True) \nvalloader = DataLoader(dataset = valdataset, batch_size = 32, shuffle = True) ","metadata":{"execution":{"iopub.status.busy":"2022-11-06T16:09:54.100624Z","iopub.execute_input":"2022-11-06T16:09:54.101079Z","iopub.status.idle":"2022-11-06T16:09:54.108034Z","shell.execute_reply.started":"2022-11-06T16:09:54.101040Z","shell.execute_reply":"2022-11-06T16:09:54.106792Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# Build model\n#####################\ninput_dim = 20\nhidden_dim = 4\nnum_layers = 1 \noutput_dim = 7\n\n\n# Here we define our model as a class\nclass LSTM(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n        super(LSTM, self).__init__()\n        # Hidden dimensions\n        self.hidden_dim = hidden_dim\n\n        # Number of hidden layers\n        self.num_layers = num_layers\n\n        # batch_first=True causes input/output tensors to be of shape\n        # (batch_dim, seq_dim, feature_dim)\n        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, bidirectional = False, batch_first=True)\n\n        # Readout layer\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        # Initialize hidden state with zeros\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n\n        # Initialize cell state\n        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n\n        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n        # If we don't, we'll backprop all the way to the start even after going through another batch\n        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n\n        # Index hidden state of last time step\n        # out.size() --> 100, 32, 100\n        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n        out = self.fc(out[:, -1, :]) \n        # out.size() --> 100, 10\n        return out\n    \nmodel = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n\nloss_fn = CrossEntropyLoss()\n\noptimiser = torch.optim.Adam(model.parameters(), lr=0.01)\nprint(model)\nprint(len(list(model.parameters())))\nfor i in range(len(list(model.parameters()))):\n    print(list(model.parameters())[i].size())","metadata":{"execution":{"iopub.status.busy":"2022-11-06T16:23:55.714953Z","iopub.execute_input":"2022-11-06T16:23:55.716178Z","iopub.status.idle":"2022-11-06T16:23:55.731198Z","shell.execute_reply.started":"2022-11-06T16:23:55.716133Z","shell.execute_reply":"2022-11-06T16:23:55.730104Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"LSTM(\n  (lstm): LSTM(20, 4, batch_first=True)\n  (fc): Linear(in_features=4, out_features=7, bias=True)\n)\n6\ntorch.Size([16, 20])\ntorch.Size([16, 4])\ntorch.Size([16])\ntorch.Size([16])\ntorch.Size([7, 4])\ntorch.Size([7])\n","output_type":"stream"}]},{"cell_type":"code","source":"model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers).to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\ncriterion = CrossEntropyLoss()\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.85)\nnum_epochs = 500\n\nbest_model_wts = model.state_dict()\nbest_metrics = 0.0\n    \n\nlosses = {'train': [], \"val\": []}\n\n# Run the training loop for defined number of epochs\nfor epoch in range(num_epochs):\n    running_loss = 0\n    processed_data = 0\n    processed_size1 = 0\n    running_loss1 = 0\n    running_corrects = 0\n    pr = []\n    cr = []\n    for batch_i, (data, target) in tqdm(enumerate(trainloader), total = len(trainloader)):\n        data = data.float()\n        target = target.type(torch.LongTensor)\n        data, target = data.to(device), target.to(device)\n        model.train()\n        optimizer.zero_grad()\n        y_pred = model(data)\n        loss = criterion(y_pred, target)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * data.size(0)\n        processed_data += data.size(0)\n    train_loss = running_loss / processed_data\n    model.eval()\n    with torch.no_grad():\n        for data, target in tqdm(valloader):\n            data = data.float()\n            target = target.type(torch.LongTensor)\n            data, target = data.to(device), target.to(device)\n            probs = model(data)\n            lossfc = criterion(probs, target) \n            running_loss1 += lossfc.item() * data.size(0)\n            processed_size1 += data.size(0)\n            \n            #preds = np.argmax(probs.cpu(), axis=1).numpy()\n            preds = np.argmax(probs.cpu(), axis=1).numpy()\n            pr.append(preds)\n            cr.append(target.cpu().numpy())\n            \n        val_loss = running_loss1 / processed_size1 \n        val_recall = recall_score(np.concatenate(cr), np.concatenate(pr), average = \"micro\")\n        \n        losses[\"train\"].append(train_loss)\n        losses[\"val\"].append(val_loss)\n        \n        if val_recall > best_metrics:\n                best_metrics = val_recall\n                best_model_wts = model.state_dict()\n    print(\"Epoch\" + \" \" + str(epoch) + \":\", \"train_loss:\" + str(train_loss), \"val_loss:\" + str(val_loss), \"val_recall:\" + str(val_recall))\n    scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2022-11-06T16:23:59.076838Z","iopub.execute_input":"2022-11-06T16:23:59.077295Z","iopub.status.idle":"2022-11-06T16:24:35.312064Z","shell.execute_reply.started":"2022-11-06T16:23:59.077259Z","shell.execute_reply":"2022-11-06T16:24:35.310386Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stderr","text":"100%|██████████| 125/125 [00:02<00:00, 51.70it/s]\n100%|██████████| 26/26 [00:00<00:00, 216.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0: train_loss:1.9424026384353639 val_loss:1.9129230082753192 val_recall:0.19879518072289157\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [00:02<00:00, 49.29it/s]\n100%|██████████| 26/26 [00:00<00:00, 224.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: train_loss:1.910560471534729 val_loss:1.8815228172095426 val_recall:0.22048192771084338\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [00:02<00:00, 52.55it/s]\n100%|██████████| 26/26 [00:00<00:00, 227.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: train_loss:1.88809144115448 val_loss:1.866205848555967 val_recall:0.2253012048192771\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [00:02<00:00, 52.51it/s]\n100%|██████████| 26/26 [00:00<00:00, 222.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: train_loss:1.8661873731613159 val_loss:1.849037160643612 val_recall:0.2433734939759036\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [00:02<00:00, 52.71it/s]\n100%|██████████| 26/26 [00:00<00:00, 234.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: train_loss:1.8475899229049682 val_loss:1.8325667955789222 val_recall:0.25060240963855424\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [00:02<00:00, 55.74it/s]\n100%|██████████| 26/26 [00:00<00:00, 227.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: train_loss:1.8330692682266236 val_loss:1.8195926465183856 val_recall:0.24819277108433735\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [00:02<00:00, 54.43it/s]\n100%|██████████| 26/26 [00:00<00:00, 226.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: train_loss:1.813220425605774 val_loss:1.8116366461098912 val_recall:0.236144578313253\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [00:02<00:00, 53.55it/s]\n100%|██████████| 26/26 [00:00<00:00, 222.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: train_loss:1.7952943296432495 val_loss:1.7977040402860527 val_recall:0.26506024096385544\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [00:02<00:00, 54.31it/s]\n100%|██████████| 26/26 [00:00<00:00, 228.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: train_loss:1.7794495754241944 val_loss:1.7719016893800483 val_recall:0.2710843373493976\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [00:02<00:00, 54.61it/s]\n100%|██████████| 26/26 [00:00<00:00, 227.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: train_loss:1.7720513372421265 val_loss:1.7731064480471324 val_recall:0.26867469879518074\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [00:02<00:00, 55.73it/s]\n100%|██████████| 26/26 [00:00<00:00, 236.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: train_loss:1.7554757804870607 val_loss:1.7451689895377103 val_recall:0.28072289156626506\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [00:02<00:00, 54.22it/s]\n100%|██████████| 26/26 [00:00<00:00, 207.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: train_loss:1.744699809074402 val_loss:1.739368252869112 val_recall:0.28313253012048195\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [00:02<00:00, 53.54it/s]\n100%|██████████| 26/26 [00:00<00:00, 230.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: train_loss:1.726126787185669 val_loss:1.7591643445463065 val_recall:0.26867469879518074\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [00:02<00:00, 53.49it/s]\n100%|██████████| 26/26 [00:00<00:00, 200.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: train_loss:1.723210702896118 val_loss:1.7468294353370206 val_recall:0.28313253012048195\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 79/125 [00:01<00:00, 48.68it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2596715178.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"#1. CNN + tabular\ndf = pd.read_csv(\"../input/tgrgrffff/train_dataset_train (4).csv\")\ndf[\"id\"] = list(range(4830))\nY = df[\"crop\"]\narea = df[\"area\"]\ngeo = df[\".geo\"]\nidxs = df[\"id\"]\ndf.drop([\"id\", \".geo\", \"crop\", \"area\"], axis = 1, inplace = True)\n\ncounter = 0\nfor cl in range(len(df.columns)):\n    counter += 1\n    if counter == 1:\n        for idx in range(len(df)):\n            if df.iloc[idx, cl] == 0:\n                df.iloc[idx, cl] = mean([df.iloc[idx, cl + 1], df.iloc[idx, cl + 2]])\n        continue\n    \n    if counter == 70:\n        for idx in range(len(df)):\n            if df.iloc[idx, cl] == 0:\n                df.iloc[idx, cl] = mean([df.iloc[idx, cl - 1], df.iloc[idx, cl - 2]])\n        continue\n        \n    for idx in range(len(df)):\n        if df.iloc[idx, cl] == 0:\n            df.iloc[idx, cl] = mean([df.iloc[idx, cl - 1], df.iloc[idx, cl + 1]])\n            \ndf['mean_all'] = df.mean(axis=1)            \ndf[\"area\"] = area\ndf[\".geo\"] = geo\ndf[\"okrug\"] = 0\ndf[\"region\"] = 0\ndef remove_punct(text):\n    \"\"\"\n        Remove the punctuation\n    \"\"\"\n    return re.sub(r'[^0-9.,]', \"\", text)\n\n\nfor i in range(len(df)):\n    dictionary = remove_punct(df[\".geo\"][i]).split(\",\")\n    dictionary = dictionary[:6]\n    dictionary = [x for x in dictionary if x != '']\n    dictionary = [float(x) for x in dictionary]\n    coords = dictionary[:2]\n    results = reverse_geocode(coords)\n    df[\"okrug\"][i] = results[\"address\"][\"Territory\"]\n    df[\"region\"][i] = results[\"address\"][\"Region\"]\ndf.drop([\".geo\"], axis = 1, inplace = True)\nct = ColumnTransformer([('one-hot-encoder', OneHotEncoder(), ['okrug', \"region\"])], remainder='passthrough')\ndf = ct.fit_transform(df)\ndf = pd.DataFrame(df)\ndf[\"id\"] = idxs\ndf[\"crop\"] = Y\ndf.head()\n                     ","metadata":{"execution":{"iopub.status.busy":"2022-11-14T22:03:17.339059Z","iopub.execute_input":"2022-11-14T22:03:17.339600Z","iopub.status.idle":"2022-11-14T22:11:31.793297Z","shell.execute_reply.started":"2022-11-14T22:03:17.339572Z","shell.execute_reply":"2022-11-14T22:11:31.791559Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_block(indexer, value, name)\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"     0    1    2    3    4    5    6    7    8    9  ...        90        91  \\\n0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.043106  0.026784   \n1  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.107641  0.111148   \n2  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.130467  0.155225   \n3  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.351907  0.570928   \n4  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.073357  0.147842   \n\n         92        93        94        95        96    97  id  crop  \n0  0.126832  0.614770  0.008857  0.081498  0.264175  20.0   0     3  \n1  0.174914  0.179612  0.113071  0.046997  0.284507  45.0   1     4  \n2  0.090607  0.054127  0.007437  0.219614  0.258649  28.0   2     2  \n3  0.073492  0.378900  0.327677  0.586523  0.300899  19.0   3     5  \n4  0.157676  0.012048  0.054223  0.017539  0.254735  33.0   4     4  \n\n[5 rows x 100 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>90</th>\n      <th>91</th>\n      <th>92</th>\n      <th>93</th>\n      <th>94</th>\n      <th>95</th>\n      <th>96</th>\n      <th>97</th>\n      <th>id</th>\n      <th>crop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.043106</td>\n      <td>0.026784</td>\n      <td>0.126832</td>\n      <td>0.614770</td>\n      <td>0.008857</td>\n      <td>0.081498</td>\n      <td>0.264175</td>\n      <td>20.0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.107641</td>\n      <td>0.111148</td>\n      <td>0.174914</td>\n      <td>0.179612</td>\n      <td>0.113071</td>\n      <td>0.046997</td>\n      <td>0.284507</td>\n      <td>45.0</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.130467</td>\n      <td>0.155225</td>\n      <td>0.090607</td>\n      <td>0.054127</td>\n      <td>0.007437</td>\n      <td>0.219614</td>\n      <td>0.258649</td>\n      <td>28.0</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.351907</td>\n      <td>0.570928</td>\n      <td>0.073492</td>\n      <td>0.378900</td>\n      <td>0.327677</td>\n      <td>0.586523</td>\n      <td>0.300899</td>\n      <td>19.0</td>\n      <td>3</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.073357</td>\n      <td>0.147842</td>\n      <td>0.157676</td>\n      <td>0.012048</td>\n      <td>0.054223</td>\n      <td>0.017539</td>\n      <td>0.254735</td>\n      <td>33.0</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 100 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from torchvision import transforms as T\n#Сначала напишем кастомный датасет\nclass CustomDataset(Dataset):\n    def __init__(self, root_dir, csv, transform = None):\n        self.transform = transform\n        self.root_dir = root_dir\n        self.csv = csv\n    \n    def __len__(self):\n        return len(self.csv)\n    \n    def __getitem__(self, index):\n        label = self.csv.iloc[index, -1]\n        img_path = os.path.join(self.root_dir, str(self.csv.iloc[index, -2])) + \".jpg\"\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        tabular = np.array(self.csv.iloc[index, :-2])\n        tabular = torch.from_numpy(tabular)\n        if self.transform:\n            image = self.transform(image = image)\n            image = image[\"image\"]\n            image = Image.fromarray(image)\n            \n        t = T.ToTensor()\n        image = t(image)\n        \n        return (image, tabular, label)","metadata":{"execution":{"iopub.status.busy":"2022-11-14T22:11:31.796142Z","iopub.execute_input":"2022-11-14T22:11:31.796549Z","iopub.status.idle":"2022-11-14T22:11:31.806403Z","shell.execute_reply.started":"2022-11-14T22:11:31.796514Z","shell.execute_reply":"2022-11-14T22:11:31.805110Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"part_75 = df.sample(frac = 0.8, random_state = 41)\nrest_part_25 = df.drop(part_75.index)","metadata":{"execution":{"iopub.status.busy":"2022-11-14T21:37:22.741737Z","iopub.execute_input":"2022-11-14T21:37:22.742777Z","iopub.status.idle":"2022-11-14T21:37:22.758990Z","shell.execute_reply.started":"2022-11-14T21:37:22.742737Z","shell.execute_reply":"2022-11-14T21:37:22.757755Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomDataset(root_dir = \"../input/imagesgeo1/images_train\", csv = part_75)\nval_dataset = CustomDataset(root_dir = \"../input/imagesgeo1/images_train\", csv = rest_part_25)\n#Создаем лоадеры\ntrainloader = DataLoader(dataset = train_dataset, batch_size = 64, shuffle = True)\nvalloader = DataLoader(dataset = val_dataset, batch_size = 64, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-11-14T21:37:22.762585Z","iopub.execute_input":"2022-11-14T21:37:22.762841Z","iopub.status.idle":"2022-11-14T21:37:22.770904Z","shell.execute_reply.started":"2022-11-14T21:37:22.762817Z","shell.execute_reply":"2022-11-14T21:37:22.770053Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Попробуем маленьку модель и посмотрим на результаты\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 5, stride = 1, padding = 2)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.pool1 = nn.MaxPool2d(kernel_size=4, stride=4, padding = 1)\n        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride = 1, padding = 1)\n        self.bn2 = nn.BatchNorm2d(128)\n        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=3)\n        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride = 1, padding = 1)\n        self.pool3 = nn.MaxPool2d(kernel_size=4, stride=4)\n        self.bn3 = nn.BatchNorm2d(256)\n        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride = 1)\n        self.bn4 = nn.BatchNorm2d(256)\n        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.relu = nn.ReLU()\n        self.fc1 = nn.Linear(98, 256)\n        self.bn5 = nn.BatchNorm1d(256)\n        self.fc2 = nn.Linear(256, 512)\n        self.bn6 = nn.BatchNorm1d(512)\n        self.bn7 = nn.BatchNorm1d(128)\n        self.fc3 = nn.Linear(2816, 512)\n        self.fc4 = nn.Linear(512, 128)\n        self.fc5 = nn.Linear(128, 7)\n        self.dp = nn.Dropout(0.3)\n        \n    def forward(self, img, tab):\n        img = self.pool1(self.relu(self.bn1(self.conv1(img))))\n        img = self.pool2(self.relu(self.bn2(self.conv2(img))))\n        img = self.pool3(self.relu(self.bn3(self.conv3(img))))\n        img = self.pool4(self.relu(self.bn4(self.conv4(img))))\n        img = img.view(-1, 256 * 3 * 3)\n        #print(img.shape) #torch.Size([64, 2304])\n        \n        tab = self.relu(self.bn5(self.fc1(tab)))\n        tab = self.relu(self.bn6(self.fc2(tab)))\n        #print(tab.shape) #torch.Size([64, 512])\n        \n        together = torch.cat((img, tab), 1)\n        #print(together.shape) #torch.Size([64, 2816])\n        together = self.dp(together)\n        together = self.relu(self.bn6(self.fc3(together)))\n        together = self.relu(self.bn7(self.fc4(together)))\n        together = self.fc5(together)\n        \n        return together","metadata":{"execution":{"iopub.status.busy":"2022-11-14T22:11:31.807864Z","iopub.execute_input":"2022-11-14T22:11:31.808455Z","iopub.status.idle":"2022-11-14T22:11:31.826079Z","shell.execute_reply.started":"2022-11-14T22:11:31.808421Z","shell.execute_reply":"2022-11-14T22:11:31.825103Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#проверка\nmodel = CNN()\nfor (i, tab, ydx) in trainloader:\n    imgs = i\n    tabs = tab.float()\n    model(imgs, tabs)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-11-12T12:35:55.225465Z","iopub.execute_input":"2022-11-12T12:35:55.226090Z","iopub.status.idle":"2022-11-12T12:36:06.672029Z","shell.execute_reply.started":"2022-11-12T12:35:55.226028Z","shell.execute_reply":"2022-11-12T12:36:06.670850Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nmodel = CNN().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\ncriterion = CrossEntropyLoss()\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.85)\nnum_epochs = 7\n\nbest_model_wts = model.state_dict()\nbest_f1 = 0.0\n    \n\nlosses = {'train': [], \"val\": []}\n\n# Run the training loop for defined number of epochs\nfor epoch in range(num_epochs):\n    running_loss = 0\n    processed_data = 0\n    processed_size1 = 0\n    running_loss1 = 0\n    running_corrects = 0\n    pr = []\n    cr = []\n    for batch_i, (data, tab, target) in tqdm(enumerate(trainloader), total = len(trainloader)):\n        data, tab, target = data.to(device), tab.to(device), target.to(device)\n        model.train()\n        tab = tab.float()\n        optimizer.zero_grad()\n        y_pred = model(data, tab)\n        loss = criterion(y_pred, target)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * data.size(0)\n        processed_data += data.size(0)\n    train_loss = running_loss / processed_data\n    model.eval()\n    with torch.no_grad():\n        for data, tab, target in tqdm(valloader):\n            data, tab, target = data.to(device), tab.to(device), target.to(device)\n            tab = tab.float()\n            probs = model(data, tab)\n            lossfc = criterion(probs, target) \n            running_loss1 += lossfc.item() * data.size(0)\n            processed_size1 += data.size(0)\n            \n            preds = np.argmax(probs.cpu(), axis=1).numpy()\n            pr.append(preds)\n            cr.append(target.cpu().numpy())\n            \n        val_loss = running_loss1 / processed_size1 \n        val_f1 = accuracy_score(np.concatenate(cr), np.concatenate(pr)) \n        \n        losses[\"train\"].append(train_loss)\n        losses[\"val\"].append(val_loss)\n        \n        if val_f1 > best_f1:\n                best_f1 = val_f1\n                best_model_wts = model.state_dict()\n    print(\"Epoch\" + \" \" + str(epoch) + \":\", \"train_loss:\" + str(train_loss), \"val_loss:\" + str(val_loss), \"val_f1:\" + str(val_f1))\n    scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2022-11-14T21:38:41.855314Z","iopub.execute_input":"2022-11-14T21:38:41.855661Z","iopub.status.idle":"2022-11-14T21:51:31.930354Z","shell.execute_reply.started":"2022-11-14T21:38:41.855633Z","shell.execute_reply":"2022-11-14T21:51:31.928457Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"100%|██████████| 61/61 [01:16<00:00,  1.25s/it]\n100%|██████████| 16/16 [00:13<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0: train_loss:1.5515738232041985 val_loss:1.4225277384862642 val_f1:0.5445134575569358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [00:46<00:00,  1.31it/s]\n100%|██████████| 16/16 [00:07<00:00,  2.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: train_loss:0.7364287468340579 val_loss:1.0956302196342753 val_f1:0.6790890269151139\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [00:47<00:00,  1.28it/s]\n100%|██████████| 16/16 [00:07<00:00,  2.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: train_loss:0.48843630284502887 val_loss:0.8516920941957036 val_f1:0.7784679089026915\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [00:47<00:00,  1.30it/s]\n100%|██████████| 16/16 [00:07<00:00,  2.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: train_loss:0.36532587022761626 val_loss:0.7090320186708778 val_f1:0.8364389233954451\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [00:46<00:00,  1.30it/s]\n100%|██████████| 16/16 [00:08<00:00,  1.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: train_loss:0.2919825821744729 val_loss:0.6860463956127996 val_f1:0.8012422360248447\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [00:43<00:00,  1.39it/s]\n100%|██████████| 16/16 [00:08<00:00,  1.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: train_loss:0.24850270389646723 val_loss:0.5792215043219967 val_f1:0.855072463768116\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [00:49<00:00,  1.24it/s]\n100%|██████████| 16/16 [00:08<00:00,  1.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: train_loss:0.21395656784252104 val_loss:0.48040016350292025 val_f1:0.8861283643892339\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [00:48<00:00,  1.25it/s]\n100%|██████████| 16/16 [00:08<00:00,  1.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: train_loss:0.20538400816991462 val_loss:0.5243580293211137 val_f1:0.8592132505175983\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [00:50<00:00,  1.21it/s]\n100%|██████████| 16/16 [00:09<00:00,  1.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: train_loss:0.18076039414166417 val_loss:0.478585221876022 val_f1:0.8747412008281573\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [00:47<00:00,  1.30it/s]\n100%|██████████| 16/16 [00:08<00:00,  1.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: train_loss:0.16438785152158875 val_loss:0.48592359333551693 val_f1:0.8592132505175983\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [00:45<00:00,  1.33it/s]\n100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: train_loss:0.1535058662943218 val_loss:0.494483201585201 val_f1:0.8509316770186336\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [00:48<00:00,  1.26it/s]\n100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: train_loss:0.14190435713430863 val_loss:0.46041739702718354 val_f1:0.8726708074534162\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [00:48<00:00,  1.26it/s]\n100%|██████████| 16/16 [00:08<00:00,  1.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: train_loss:0.1309569633525351 val_loss:0.4767776448780952 val_f1:0.8612836438923396\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▍        | 9/61 [00:07<00:41,  1.26it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/2431661551.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mcr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"from torchvision import transforms as T\n#Сначала напишем кастомный датасет\nclass CustomDataset(Dataset):\n    def __init__(self, root_dir, csv, transform = None):\n        self.transform = transform\n        self.root_dir = root_dir\n        self.csv = csv\n    \n    def __len__(self):\n        return len(self.csv)\n    \n    def __getitem__(self, index):\n        img_path = os.path.join(self.root_dir, str(self.csv.iloc[index, -1])) + \".jpg\"\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        tabular = np.array(self.csv.iloc[index, :-1])\n        tabular = torch.from_numpy(tabular)\n        if self.transform:\n            image = self.transform(image = image)\n            image = image[\"image\"]\n            image = Image.fromarray(image)\n            \n        t = T.ToTensor()\n        image = t(image)\n        \n        return (image, tabular)","metadata":{"execution":{"iopub.status.busy":"2022-11-14T22:26:14.825560Z","iopub.execute_input":"2022-11-14T22:26:14.825948Z","iopub.status.idle":"2022-11-14T22:26:14.835551Z","shell.execute_reply.started":"2022-11-14T22:26:14.825914Z","shell.execute_reply":"2022-11-14T22:26:14.834316Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"val_dataset = CustomDataset(root_dir = \"../input/imagesgeo1/images_test\", csv = df)\nvalloader = DataLoader(dataset = val_dataset, batch_size = 120, shuffle = False)\npredict = []\nmodel.eval()\nwith torch.no_grad():\n    for data, tab in tqdm(valloader):\n            data, tab = data.to(device), tab.to(device)\n            tab = tab.float()\n            probs = model(data, tab)\n            predict.append(np.argmax(probs.cpu(), axis=1).numpy())\n            \npreds = np.concatenate(predict)\npreds = preds.tolist()\nsub = pd.read_csv(\"../input/rthhrfhfghghfg/sample_solution.csv\")\nsub[\"crop\"] = preds\nsub.to_csv(\"CNN_LABELS_TEST.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-11-14T22:26:19.971788Z","iopub.execute_input":"2022-11-14T22:26:19.972224Z","iopub.status.idle":"2022-11-14T22:26:51.909701Z","shell.execute_reply.started":"2022-11-14T22:26:19.972188Z","shell.execute_reply":"2022-11-14T22:26:51.908615Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|██████████| 18/18 [00:31<00:00,  1.77s/it]\n","output_type":"stream"}]}]}